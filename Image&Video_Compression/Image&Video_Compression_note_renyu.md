## End-to-end Optimized Image Compression
2016年挂ArXiv 2017年 ICLR 奠基论文，确定了深度学习图像压缩方法的基本模型，后续的研究基本遵循了这个框架在改进。  
### 模型框架
分了三个部分：analysis transform分析变换（编码器），uniform quantizer均匀量化器（量化器），synthesis transform合成变换（解码器）  
* 分析变换重复了三段卷积线性滤波器+非线性激活函数，那就是实现卷积神经网络特征提取从而实现压缩。还提出了特别适合图像重建问题的归一化层GDN Generalized Divisive Normalization，不像是BN层会引入噪声。（TODO：GDN层原理）  
* 均匀量化器是输出的连续值为了方便存储传输要化有限整数，但是就会因为不可导造成无法反向传播。所以这里引入了代理函数，训练过程中不进行量化，而是使用均匀噪声来模拟量化造成的误差（TODO：有推导不太理解），就可以求导。  
* 合成变换，基本就是分析变换网络结构倒转过来恢复实现解码，GDN层变成对应的IGDN层，降采样变成升采样。  

## Learning Convolutional Networks for Content-weighted Image Compression
2018年 CVPR经典论文  
香港理工大学 Li Mu  
### 问题：  
用CNN做端到端图像压缩，存在的困难有  
* 1.量化器是不可导的，就没法做反向传播；  
* 2.需要离散熵估计来做速率控制（这个离散熵估计的概念没有找到准确出处和含义，应该是统计每个符号出现的频率作为概率计算信息熵再离散化，得到的和当做码率的大小），这一步也不可导  
### 方法：  
* 1.图像不同部分重要性不同，所以比特率分配也应该不同，引入importance map来替代离散熵估计从而解决问题2（TODO：为什么重要性图就可以代替熵估计，通过权重控制比特率分配是怎么实现的？）  
看网络结构importance map的实现是一个旁路的分支结构，编码器的输出分了一路输入重要性图网络得到一个包含每一个像素点重要权重的图，这个图量化后作为一个mask掩码表去乘二值化的输出，实现所谓的内容重要性加权。  
* 2.用二值化对编码器的输出进行量化，反向传播中再引入二进制运算的代理函数，就可导从而可以反向传播了（TODO：这里可以参考BNN 二值神经网络，能极大减少计算量和内存开销，但这里量化原理没看懂得专门研究下，直观感觉直接把很高维的提取特征用二值化表示还能保持一定的效果很不可思议），解决了问题1。  
### 效果：
在低比特率的图像压缩中，SSIM优于JPEG、JPEG 2000，边缘更清晰、纹理更丰富、伪影更少。  
### 想法：
给我感觉用深度学习解决一些本不适用深度学习的任务时，关键是解决任务流程中个别步骤不可导的问题，引入不同的可导方法来近似实现原步骤效果并支持反向传播跑通。所以就要理解替代方法为什么可以近似原步骤效果？为什么可以求导？  

## End-to-End Optimized ROI Image Compression
2020年TIP经典 ROI图像压缩论文  
不同于之前传统的ROI图像压缩方法是分两步先做ROI获得ROI区域作为Mask之后再送入编码器处理，直观好理解但是没法放在一起优化，这篇文章提出了把ROI和encoder做在一起的框架。（TODO：这里我还不是很理解为什么做在一起就可以更好的优化，是指ROI区域预测结果也是动态调整的吗？）  
### 网络结构：
看网络结构应该和Learning Convolutional Networks for Content-weighted Image Compression文章中的importance map的做法类似，是encoder的后半部分输出分两路，一路正常出多尺度representation特征，一路输入旁路分支预测出ROI掩码图（二值的），然后组合在一起（说是element filtering operation不知道是不是就加权乘）。这里说得到的是implicit ROI Mask（TODO：隐式是什么意思？）。  
使用ROI做码率分配的实现原理是在encoder中加入了MSD多尺度分解块来实现的，decoder对应用IMSD（TODO：MSD是另一篇文章提出的可以看下原理）。  
### 想法：
我理解做ROI图像压缩就是想办法把生成ROI掩码图的网络结构加入网络，实现图像不同部分对Loss的影响不同就可以实现多保留主体牺牲背景的效果。  